# 基本流程
模式
Ultralytics YOLO 模型以不同的模式运行，每种模式都专为模型生命周期的特定阶段而设计：

训练：在自定义数据集上训练 YOLO 模型。
Val：验证已训练的 YOLO 模型。
预测：使用训练好的 YOLO 模型对新图像或视频进行预测。
导出：导出 YOLO 模型以进行部署。
跟踪：使用 YOLO 模型实时跟踪对象。
基准测试: 对 YOLO 导出（ONNX、TensorRT 等）的速度和准确性进行基准测试。

# YOLO 验证模式详解

## 一、验证模式概述

**Val 模式** 是 YOLO 训练流程中**关键的质量评估环节**，用于：

1. **评估模型性能** - 在训练后检查模型在未见过的数据上的表现
2. **防止过拟合** - 确保模型泛化能力强，而不仅仅记住训练集
3. **超参数调优** - 作为调整训练参数的依据
4. **模型选择** - 选择最佳模型权重用于部署

## 二、两种验证方式对比

### 方式1：训练后验证（使用训练时相同的验证集）
```python
from ultralytics import YOLO

# 加载模型结构（非预训练）
model = YOLO("yolo26n.yaml")  # 随机初始化权重

# 训练模型
model.train(data="coco8.yaml", epochs=5)

# 验证：使用训练时相同的验证集
# 这会自动使用coco8.yaml中定义的验证集
model.val()
```

**特点**：
- ✅ 使用训练时已划分好的验证集
- ✅ 评估模型对训练过程的适应性
- ❌ 无法测试模型在全新数据上的表现

### 方式2：在其他数据集上验证
```python
from ultralytics import YOLO

# 加载模型
model = YOLO("yolo26n.yaml")

# 训练
model.train(data="coco8.yaml", epochs=5)

# 验证：使用完全不同的数据集
# 测试模型泛化能力
model.val(data="path/to/separate/data.yaml")
```

**特点**：
- ✅ 测试模型真正的泛化能力
- ✅ 发现训练-测试分布不一致的问题
- ✅ 更接近实际部署场景
- ❌ 需要额外准备验证数据集

## 三、验证输出的关键指标

运行 `model.val()` 后会输出重要的评估指标：

```
Class      Images  Instances      P      R      mAP50  mAP50-95
all          1000       6432   0.789  0.772    0.803     0.612
person       1000       1084   0.874  0.842    0.883     0.651
car          1000       1428   0.823  0.801    0.842     0.654
...
```

**关键指标解释**：
- **P (Precision)**：精确率，预测为正的样本中实际为正的比例
- **R (Recall)**：召回率，实际为正的样本中被正确预测的比例
- **mAP50**：IoU阈值为0.5时的平均精度
- **mAP50-95**：IoU阈值从0.5到0.95的平均精度（更严格）

## 四、实际应用的最佳实践

### 推荐的工作流程：
```python
from ultralytics import YOLO

# 1. 加载预训练模型（效果更好）
model = YOLO("yolo26n.pt")  # 加载预训练权重

# 2. 训练模型
results = model.train(
    data="my_dataset.yaml",  # 自定义数据集
    epochs=100,
    imgsz=640,
    batch=16,
    save=True,               # 保存最佳模型
    val=True,                # 训练中自动验证
    patience=10              # 早停机制
)

# 3. 在多个数据集上进行验证
# 3.1 在原始验证集上验证
print("=== 原始验证集结果 ===")
val_results = model.val()  # 使用训练时的验证集

# 3.2 在新的测试集上验证
print("=== 独立测试集结果 ===")
test_results = model.val(
    data="test_data.yaml",  # 独立的测试集
    split="test",           # 使用测试集
    save_json=True          # 保存详细结果
)

# 3.3 在不同域的数据上验证（测试泛化）
print("=== 跨域测试结果 ===")
cross_domain_results = model.val(
    data="different_domain.yaml",
    name="cross_domain_eval"  # 保存到单独目录
)
```

### 验证参数详解：
```python
results = model.val(
    data="dataset.yaml",      # 数据集配置文件
    split="val",              # 使用哪个数据集划分：val, test, 或train
    imgsz=640,                # 推理图像大小
    batch=32,                 # 批量大小
    save_json=False,          # 是否保存结果为JSON文件
    save_hybrid=False,        # 是否保存混合标签
    conf=0.001,               # 置信度阈值
    iou=0.6,                  # NMS IoU阈值
    max_det=300,              # 每张图最大检测数
    half=True,                # 使用半精度推理
    device=None,              # 设备，如0,1,2,3或"cpu"
    dnn=False,                # 使用OpenCV DNN进行ONNX推理
    plots=True,               # 绘制混淆矩阵等图表
    rect=False,               # 矩形推理
    split="val"               # 数据集划分
)
```

## 五、验证结果的使用

### 1. 模型选择与早停
```python
# 训练时监控验证指标，选择最佳模型
model.train(
    data="dataset.yaml",
    epochs=100,
    patience=20,  # 20个epoch验证指标无改善则停止
    save_period=5,  # 每5个epoch保存一次
    plots=True     # 生成训练验证曲线
)
```

### 2. 模型比较
```python
# 比较不同模型在同一验证集上的表现
models = {
    "yolo26n": "yolo26n.pt",
    "yolo26s": "yolo26s.pt",
    "yolo26m": "yolo26m.pt"
}

results = {}
for name, path in models.items():
    model = YOLO(path)
    results[name] = model.val(data="test_data.yaml")
    
# 分析哪个模型最适合你的任务
```

### 3. 部署前的最终验证
```python
# 部署前在多个场景下验证
def comprehensive_validation(model_path):
    model = YOLO(model_path)
    
    validation_scenarios = [
        ("daytime", "day_data.yaml"),
        ("night", "night_data.yaml"),
        ("rainy", "rainy_data.yaml"),
        ("crowded", "crowded_data.yaml")
    ]
    
    for scenario_name, data_path in validation_scenarios:
        print(f"\n验证场景: {scenario_name}")
        metrics = model.val(
            data=data_path,
            name=f"final_validation/{scenario_name}"
        )
        print(f"mAP50-95: {metrics.box.map:.4f}")
    
    return True

# 执行全面验证
comprehensive_validation("best.pt")
```

## 六、验证的注意事项

1. **数据泄露**：确保验证集与训练集完全独立
2. **分布匹配**：验证集应代表实际应用场景
3. **数据质量**：验证集的标注质量直接影响评估结果
4. **多指标评估**：不要只看mAP，还要看各个类别的表现
5. **计算成本**：大规模验证集可能需要较长时间

## 七、总结

验证是模型开发流程中**必不可少**的环节，它：
- ✅ 提供客观的性能指标
- ✅ 帮助选择最佳模型
- ✅ 发现训练中的问题
- ✅ 确保模型能够泛化到新数据

建议在**项目每个关键节点**都进行验证，包括：
1. 训练过程中的定期验证
2. 训练结束后的综合验证
3. 不同数据集上的泛化验证
4. 部署前的最终验证

# YOLO 预测模式详解

## 一、预测模式概述

**Predict 模式** 是 YOLO 模型的核心应用环节，用于使用训练好的模型进行**实时推理和预测**。主要功能包括：

1. **目标检测** - 识别图像/视频中的物体并标注边界框
2. **实例分割** - 识别物体并生成像素级掩码
3. **姿态估计** - 检测人体关键点
4. **分类** - 对图像进行分类

## 二、预测模式的多种输入方式

### 1. **基本预测示例**
```python
from ultralytics import YOLO

# 加载训练好的模型
model = YOLO("model.pt")

# 对单张图像进行预测
results = model.predict(source="bus.jpg")
```

### 2. **多种输入源支持**
```python
# 1. 摄像头实时预测
results = model.predict(source="0")  # 0表示默认摄像头

# 2. 文件夹批量预测
results = model.predict(source="folder", show=True)  # 显示预测结果

# 3. 视频文件预测
results = model.predict(source="video.mp4")

# 4. 网络图片
results = model.predict(source="https://ultralytics.com/images/bus.jpg")

# 5. PIL图像
from PIL import Image
im1 = Image.open("bus.jpg")
results = model.predict(source=im1, save=True)  # 保存带标注的图像

# 6. OpenCV读取的图像（numpy数组）
import cv2
im2 = cv2.imread("bus.jpg")
results = model.predict(source=im2, save=True, save_txt=True)

# 7. 批量图像列表
results = model.predict(source=[im1, im2])
```

## 三、预测结果的解析与使用

### 1. **Results 对象结构**
```python
results = model.predict(source="image.jpg")

# 获取第一个结果（如果是单张图像）
result = results[0]

# Results对象包含以下主要属性：
```

### 2. **目标检测结果解析**
```python
# 边界框信息
result.boxes.xyxy     # [N, 4] 左上角和右下角坐标 (x1, y1, x2, y2)
result.boxes.xywh     # [N, 4] 中心点和宽高 (x_center, y_center, width, height)
result.boxes.xyxyn    # [N, 4] 归一化坐标 (0-1)
result.boxes.xywhn    # [N, 4] 归一化中心点和宽高
result.boxes.conf     # [N, 1] 置信度分数
result.boxes.cls      # [N, 1] 类别索引

# 获取类别名称
class_names = model.names  # 类别字典
detected_classes = [class_names[int(cls)] for cls in result.boxes.cls]

# 具体使用示例
boxes = result.boxes.xyxy.cpu().numpy()  # 转换为numpy数组
confidences = result.boxes.conf.cpu().numpy()
classes = result.boxes.cls.cpu().numpy().astype(int)

for box, conf, cls in zip(boxes, confidences, classes):
    x1, y1, x2, y2 = box
    label = f"{model.names[cls]}: {conf:.2f}"
    print(f"检测到: {label}, 位置: [{x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}]")
```

### 3. **实例分割结果解析**
```python
# 掩码信息
result.masks.data      # [N, H, W] 二值掩码张量
result.masks.xy        # 多边形坐标（像素值），列表长度N
result.masks.xyn       # 归一化多边形坐标

# 使用示例
if result.masks is not None:
    masks = result.masks.data.cpu().numpy()  # 转换为numpy数组
    for i, mask in enumerate(masks):
        print(f"第{i}个物体的掩码形状: {mask.shape}")
```

### 4. **分类结果解析**
```python
# 分类概率
result.probs  # [num_classes] 每个类别的概率

# 使用示例
if result.probs is not None:
    top5_indices = result.probs.top5  # 前5个最可能的类别索引
    top5_probs = result.probs.top5conf  # 对应的置信度
    for idx, prob in zip(top5_indices, top5_probs):
        print(f"类别: {model.names[idx]}, 概率: {prob:.4f}")
```

## 四、内存优化：流式处理

### **问题**：大量图像时内存占用过高
```python
# 默认返回列表（可能内存爆炸）
results = model.predict(source="large_folder")  # 返回包含所有结果的列表
```

### **解决方案**：使用流式处理
```python
# 使用生成器，节省内存
results = model.predict(source="large_folder", stream=True)

for result in results:
    # 逐个处理结果，不一次性加载所有结果到内存
    boxes = result.boxes
    # 处理当前结果...
    print(f"处理完成: {result.path}")
```

## 五、高级预测参数配置

```python
results = model.predict(
    source="input.jpg",
    
    # 基本参数
    conf=0.25,           # 置信度阈值
    iou=0.7,            # NMS的IoU阈值
    imgsz=640,          # 推理图像大小
    device=None,        # 设备：0,1,2,3或"cpu"
    max_det=1000,       # 每张图像最大检测数
    half=False,         # 半精度推理（FP16）
    
    # 可视化参数
    show=False,         # 显示结果
    save=False,         # 保存图像
    save_txt=False,     # 保存标签为txt文件
    save_conf=False,    # 保存标签时包含置信度
    save_crop=False,    # 保存裁剪的检测框
    show_labels=True,   # 显示标签
    show_conf=True,     # 显示置信度
    boxes=True,         # 显示边界框
    
    # 输出参数
    augment=False,      # 测试时数据增强
    visualize=False,    # 可视化特征图
    agnostic_nms=False, # 类别无关的NMS
    retina_masks=False, # 使用高分辨率掩码
    show_boxes=True,    # 显示边界框
    show_masks=True,    # 显示分割掩码
    show_keypoints=True,# 显示关键点
    show_probs=True,    # 显示分类概率
    
    # 跟踪参数（视频）
    tracker="bytetrack.yaml",  # 使用跟踪器
    persist=True               # 保持跟踪ID
)
```

## 六、实战应用示例

### 示例1：实时摄像头检测
```python
import cv2
from ultralytics import YOLO

# 加载模型
model = YOLO("yolo26n.pt")

# 打开摄像头
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # 进行预测
    results = model(frame, conf=0.5, verbose=False)
    
    # 获取第一个结果
    result = results[0]
    
    # 在图像上绘制结果
    annotated_frame = result.plot()  # 自动绘制所有检测
    
    # 显示结果
    cv2.imshow("YOLO Real-time Detection", annotated_frame)
    
    # 按'q'退出
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### 示例2：批量处理并保存结果
```python
from ultralytics import YOLO
import os

# 加载模型
model = YOLO("model.pt")

# 批量处理文件夹
input_folder = "input_images"
output_folder = "output_images"

# 确保输出文件夹存在
os.makedirs(output_folder, exist_ok=True)

# 进行预测
results = model.predict(
    source=input_folder,
    save=True,
    save_txt=True,
    save_conf=True,
    project=output_folder,
    name="detections",
    exist_ok=True
)

# 打印统计信息
print(f"处理了 {len(results)} 张图片")
print(f"结果保存在: {output_folder}/detections")
```

### 示例3：自定义后处理
```python
from ultralytics import YOLO
import cv2

model = YOLO("model.pt")

# 预测
results = model("image.jpg")

# 获取原始图像
result = results[0]
original_image = result.orig_img

# 自定义绘制
for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):
    x1, y1, x2, y2 = map(int, box[:4])
    label = f"{model.names[int(cls)]} {conf:.2f}"
    
    # 绘制边界框
    cv2.rectangle(original_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    # 绘制标签背景
    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
    cv2.rectangle(original_image, (x1, y1-25), (x1+text_width, y1), (0, 255, 0), -1)
    
    # 绘制文本
    cv2.putText(original_image, label, (x1, y1-5), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)

# 保存自定义结果
cv2.imwrite("custom_output.jpg", original_image)
```

## 七、性能优化技巧

### 1. **批处理加速**
```python
# 使用批处理提高GPU利用率
results = model.predict(source="folder", batch=16, stream=False)
```

### 2. **使用TensorRT加速**
```python
# 先导出为TensorRT格式
model.export(format="engine", imgsz=640)

# 加载TensorRT模型
trt_model = YOLO("model.engine")
results = trt_model.predict(source="image.jpg")
```

### 3. **半精度推理**
```python
# 使用FP16减少内存和加速
results = model.predict(source="image.jpg", half=True)
```

### 4. **边缘设备优化**
```python
# 使用更小的模型
model = YOLO("yolo26n.pt")  # nano版本

# 降低图像分辨率
results = model.predict(source="image.jpg", imgsz=320)
```

## 八、常见问题解决

### 问题1：内存不足
```python
# 解决方案：使用流式处理
results = model.predict(source="video.mp4", stream=True)

# 或者降低批处理大小
results = model.predict(source="folder", batch=4)
```

### 问题2：推理速度慢
```python
# 解决方案：
# 1. 使用GPU
results = model.predict(source="image.jpg", device=0)

# 2. 降低图像分辨率
results = model.predict(source="image.jpg", imgsz=320)

# 3. 导出为优化格式
model.export(format="onnx")  # 或 "engine", "tflite"
```

### 问题3：结果不准确
```python
# 解决方案：
# 1. 调整置信度阈值
results = model.predict(source="image.jpg", conf=0.3)

# 2. 使用测试时数据增强
results = model.predict(source="image.jpg", augment=True)

# 3. 调整NMS阈值
results = model.predict(source="image.jpg", iou=0.5)
```

## 九、总结

预测模式是 YOLO 模型**实际应用的核心**，支持：

1. **多种输入源** - 图像、视频、摄像头、URL、文件夹等
2. **多种输出格式** - 边界框、掩码、关键点、类别概率
3. **灵活的配置** - 丰富的参数满足不同需求
4. **内存优化** - 流式处理支持大规模数据
5. **高性能推理** - GPU加速、批处理、模型优化

**关键建议**：
- 根据应用场景选择合适的输入方式和参数
- 使用 `stream=True` 处理大量数据
- 合理设置 `conf` 和 `iou` 阈值平衡精度和召回率
- 利用 `result.plot()` 快速可视化结果
- 根据部署环境选择合适的模型格式和优化策略